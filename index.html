<!DOCTYPE html>
<html lang="ja">
  <head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=720, initial-scale=1">
    <!-- Google Search Console -->
    <meta name="google-site-verification" content="ls7kuvIKSqVa_dcixqKvFwl393swvYMkHCkG-xtlCj0">
    <title>mirror</title>
    <link rel="icon" href="https://neos21.github.io/favicon.ico">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@neos21/neos-normalize@2.0.1/neos-normalize.min.css">
    <!-- Global Site Tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LP3ZQV2R3M"></script>
    <script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date());gtag('config','G-LP3ZQV2R3M');gtag('config','UA-106501-6');</script>
    <!-- Google AdSense -->
    <script data-ad-client="ca-pub-6475907504235292" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <style>

*,
::before,
::after {
  box-sizing: border-box;
}

body {
  margin: 1rem;
  color: #000;
  background: #fff;
}

h1 {
  font-size: 1.2rem;
  margin: 0;
}

p {
  margin: 0 0 1rem;
}

h2 {
  font-size: 1rem;
  margin: 0;
}

.preview {
  display: grid;
  grid-template-columns: 1fr 1fr;
  margin: 0 0 1rem;
}

.preview > div {
  border-right: 1rem solid #fff;  /* Force Margin */
}

#video {
  background: #ffc;
}

#canvas {
  background: #cff;
}

#error-message {
  color: #f00;
}

    </style>
  </head>
  <body>

<h1>カメラキャプチャー</h1>
<p>
  <button id="start" type="button" disabled>Start</button>
  <button id="stop" type="button" disabled>Stop</button>
  <span id="status">Initializing...</span>
  <span id="error-message"></span>
</p>

<div class="preview">
  <div>
    <div><canvas id="canvas" width="720" height="480" ></canvas></div>
  </div>
  <div>
    <div hidden><video id="video" width="720" height="480" playsinline muted autoplay></video></div>
  </div>
</div>

<script>

// https://docs.opencv.org/3.4.0/df/d6c/tutorial_js_face_detection_camera.html

// Video Settings
const widthC  = 720;
const heightC = 480;
const width  = 720;
const height = 480;
const fps = 30;

// Globals
let videoCapture = null;
let stream = null;
let isStreaming = false;
let matSrc  = null;
let matDst  = null;
let matGrey = null;
let faces = null;
let classifier = null;

let vecImage = [];
let currentImages = [];
let index = 0;
let index_max = 2;
let turn = 0;
let nextImage = null;
let startTime;
let startTimeInterval = 1000*30;

let oldState = 0;
let startActionTime;
let startActionTimeInterval = 100*1;

let slowcount = 0;

// Elements
const videoElem  = document.getElementById('video');
const canvasElem = document.getElementById('canvas');
const startButtonElem = document.getElementById('start');
const stopButtonElem  = document.getElementById('stop');
const statusElem = document.getElementById('status');

// https://docs.opencv.org/3.4.0/haarcascade_frontalface_default.xml
const faceCascadeFile = './haarcascade_frontalface_default.xml';

var music = new Audio();

// ================================================================================

/** On OpenCV.js Loaded */
function onCvLoaded() 
{
  console.log('on OpenCV.js Loaded', cv);
  
  cv.onRuntimeInitialized = onReady;  // Not Working...
  statusElem.innerText = 'On OpenCV.js Loaded';

    music.preload = "auto";
    music.src = "./data/crow7.mp3";
    music.load();
}

/** On Ready */
function onReady() 
{
  console.log('On Ready');
  
  // Set Element Size
  canvasElem.width  = widthC;
  canvasElem.height = heightC;
  videoElem.width  = width;
  videoElem.height = height;

  // Start Video Capture
  videoCapture = new cv.VideoCapture(videoElem);
  // Load XML File With XHR
  const utils = new Utils('error-message');  // Set Element ID
  utils.createFileFromUrl(faceCascadeFile, faceCascadeFile, () => {
    console.log('Face Cascade File Loaded');
  });
  // Set Button Events
  startButtonElem.addEventListener('click', onStart);
  startButtonElem.disabled = false;
  stopButtonElem.addEventListener('click', onStop);
  stopButtonElem.disabled  = true;
  
  statusElem.innerText = 'Ready';
};

/** On Window Loaded */
window.addEventListener('load', () => {
  console.log('Window Loaded');
  
  onReady();  // cv.onRuntimeInitialized Is Not Working, So This Is Fallback
});

/** On Start */
function onStart() {
  navigator.mediaDevices.getUserMedia({
    video: true,
    audio: false
  })
    .then((_stream) => {

      console.log('On Start : Success');
      
      stream = videoElem.srcObject = _stream;
      videoElem.play();
      
      matSrc  = new cv.Mat(height, width, cv.CV_8UC4);  // For Video Capture
      matDst  = new cv.Mat(height/3.5, width/3.5, cv.CV_8UC4);  // For Canvas Preview
      matGrey = new cv.Mat();


  for ( let i=0; i<30*5; i++ )
  {
    let mat  = new cv.Mat(height, width, cv.CV_8UC4);  // For Video Capture

    vecImage[i] = mat;
    currentImages[i] = mat;
  }


      faces = new cv.RectVector();
      classifier = new cv.CascadeClassifier();
      // Load Pre-Trained Classifiers
      if( classifier.load(faceCascadeFile) )
	{
		console.log("faceCascadeFile ok!");
	}
      
      // Start Process Video
      setTimeout(processVideo, 0);
      
      isStreaming = true;
      startButtonElem.disabled = true;
      stopButtonElem.disabled  = false;
    })
    .catch((error) => {
      console.error('On Start : Error', error);
    });

    startTime = Date.now();
}

/** On Stop */
function onStop() 
{
  console.log('On Stop');
  
  videoElem.pause();
  videoElem.srcObject = null;
  stream.getVideoTracks()[0].stop();
  
  isStreaming = false;
  startButtonElem.disabled = false;
  stopButtonElem.disabled  = true;
}

/** Process Video */

let count = 0;

function processVideo() 
{
  if(!isStreaming) {
    console.log('Process Video : Streaming Stopped');
    
    matSrc.delete();
    matDst.delete();
    matGrey.delete();
    faces.delete();
    classifier.delete();
    return;
  }

  const begin = Date.now();
  videoCapture.read(matSrc);  // Capture Video Image To Mat Src

  cv.resize( matSrc, matDst, matDst.size() ); 

  cv.cvtColor(matDst, matGrey, cv.COLOR_RGBA2GRAY, 0);  // Get Grey Image

  classifier.detectMultiScale(matGrey, faces, 1.1, 3, 0);  // Detect Faces

  cv.flip( matSrc, matSrc, 1 );
  cv.imshow('canvas', matSrc);  // Set Element ID

//---------------------------------------------------------------------
  if( Date.now()-startTime >= startTimeInterval )
{
  if ( faces.size() == 0 )
  {
    if ( currentImages.length > 0 )
    {        
let m = currentImages[index];
if( !( m.data[0]==0 && m.data[1]==0 && m.data[2]==0 ) )
{
if( oldState == 0 )
{
startActionTime = Date.now();
}
  if( Date.now()-startActionTime >= startActionTimeInterval )
  {
//let index2 = parseInt(index*0.5)*2;
      cv.imshow('canvas', currentImages[index] );
      slowcount++;

if( slowcount > 2 )
{
slowcount = 0;
      if ( turn == 0 )
      {
        index--;
        if ( index <= 1 )
        {
          index = 1;
          turn = 1;
        }
      } else
      {
        index++;
        if ( index >= index_max-1 )
        {
          index = index_max-1;
          turn = 0;
        }
      }
}
  }
oldState = 1;
}
    }
  }
  else
  {
let m = matSrc;
if( !( m.data[0]==0 && m.data[1]==0 && m.data[2]==0 ) )
{
    slowcount = 0;
    index = vecImage.length-1;
    turn = 0;

    nextImage = currentImages[0];
    currentImages.shift();
    matSrc.copyTo( nextImage );
    currentImages.push( nextImage );

    if ( index_max < vecImage.length )
    {
      index_max++;
    }
}
oldState = 0;
  }
}
//---------------------------------------------------------------------


  // Loop
  const delay = 1000 / fps - (Date.now() - begin);
  setTimeout(processVideo, delay);
}

</script>
<!-- https://docs.opencv.org/3.4.0/utils.js -->
<script src="./utils.js"></script>
<!-- https://docs.opencv.org/3.4.0/opencv.js -->
<script src="./opencv.js" onload="onCvLoaded();"></script>

  </body>
</html>
